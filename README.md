# ğŸ¥ Insurance Charges Prediction

This project explores a health insurance dataset to understand the factors influencing medical charges and build predictive models.

A logarithmic transformation was applied to the target variable (charges) to handle skewness and reduce the effect of outliers, leading to improved model performance.

ğŸ“Œ Dataset Description

age â†’ Age of the individual

sex â†’ Male/Female

bmi â†’ Body Mass Index (health/obesity measure)

children â†’ Number of dependents

smoker â†’ Smoking status (yes/no)

region â†’ Residential area (northeast, northwest, southeast, southwest)

charges â†’ Medical insurance cost (target, log-transformed for modeling)

ğŸ¯ Purpose of Analysis

Predict medical insurance charges using regression models.

Compare Linear Regression, Ridge, and Lasso after applying log transformation.

Evaluate models using RÂ², MAE, MSE, and RMSE.

ğŸ“Š Results Summary After Log Transformation

Linear Regression

RÂ²: 0.803 â†’ Explains ~80% variance

MAE: 0.275

MSE: 0.177

Ridge Regression

RÂ²: 0.803

MAE: 0.28

RMSE: 0.42

Lasso Regression

RÂ²: 0.803

MAE: 0.27

RMSE: 0.42

ğŸ“Œ Key Insight: Log transformation improved stability and reduced the impact of extreme high-cost outliers. All three models perform very similarly, with Lasso offering slight feature selection benefits.

MAE â‰ˆ 0.27 (log scale) â†’ When exponentiated, this corresponds to exp(0.27) â‰ˆ 1.30.

This means that on average, the modelâ€™s predictions are about 30% higher or lower than the actual insurance charges.

ğŸ“ˆ Visualizations

Predicted vs Actual (log-charges) scatter plot shows better alignment with the perfect fit line compared to the untransformed version.

Distribution of residuals is more normal after transformation.

ğŸš€ Next Steps

Explore non-linear models (Random Forest, XGBoost) for further improvement.

ğŸ‘©â€ğŸ’» Author

Project by Sonia Firdous.

Special thanks to my teacher Aqsa Moiz for guidance ğŸ™
