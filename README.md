# ğŸ¥ Insurance Charges Prediction

This project explores a health insurance dataset to understand the factors influencing medical charges and build predictive models.

A logarithmic transformation was applied to the target variable (charges) to handle skewness and reduce the effect of outliers, leading to improved model performance.

ğŸ“Œ Dataset Description

age â†’ Age of the individual

sex â†’ Male/Female

bmi â†’ Body Mass Index (health/obesity measure)

children â†’ Number of dependents

smoker â†’ Smoking status (yes/no)

region â†’ Residential area (northeast, northwest, southeast, southwest)

charges â†’ Medical insurance cost (target, log-transformed for modeling)

ğŸ¯ Purpose of Analysis

Predict medical insurance charges using regression models.

Compare Linear Regression, Ridge, Lasso, and Polynomial Regression after applying log transformation.

Evaluate models using RÂ², MAE, MSE, and RMSE.

ğŸ“Š Results Summary After Log Transformation

Linear Regression

RÂ²: 0.803 â†’ Explains ~80% variance

MAE: 0.275

MSE: 0.177

Ridge Regression

RÂ²: 0.803

MAE: 0.28

RMSE: 0.42

Lasso Regression

RÂ²: 0.803

MAE: 0.27

RMSE: 0.42

Polynomial Regression

RÂ²: 0.861 â†’ Higher than Linear, Ridge, and Lasso

Captures non-linear relationships between features and the target

More flexible but less interpretable, with potential risk of overfitting if polynomial degree is too high

ğŸ“Œ Key Insights

Log transformation improved stability and reduced the impact of extreme high-cost outliers.

Linear, Ridge, and Lasso perform very similarly, with Lasso offering slight feature selection benefits.

Polynomial Regression outperforms all linear-based models, showing that non-linear patterns exist in the data.

However, interpretability decreases and careful degree selection is important to avoid overfitting.

MAE â‰ˆ 0.27 (log scale) â†’ When exponentiated, this corresponds to exp(0.27) â‰ˆ 1.30.

**This means that on average, the Polynomial regression modelâ€™s predictions are about 22 % higher or lower than the actual insurance charges.**

ğŸ“ˆ Visualizations

Predicted vs Actual (log-charges)

Shows closer alignment with the perfect-fit line in Polynomial Regression compared to Linear Regression.

ğŸš€ Next Steps

Explore advanced non-linear models (Random Forest, XGBoost) for further improvement.

Compare them with Polynomial Regression to check trade-offs between accuracy and interpretability.

ğŸ‘©â€ğŸ’» Author

Project by Sonia Firdous.

Special thanks to my teacher Aqsa Moiz for guidance ğŸ™
